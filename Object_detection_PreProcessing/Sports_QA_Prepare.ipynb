{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import io\n",
    "import json\n",
    "import os, sys\n",
    "import contextlib2\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from object_detection.dataset_tools import tf_record_creation_util\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"Sport_QA/Annotations\"\n",
    "path = [os.path.join(path,x) for x in os.listdir(path)]\n",
    "im_path = \"Sport_QA/Images\"\n",
    "im_path = [os.path.join(im_path,x) for x in os.listdir(im_path)]\n",
    "\n",
    "test_path = \"Sport_QA/test_Annotations\"\n",
    "test_path = [os.path.join(test_path,x) for x in os.listdir(test_path)]\n",
    "test_im_path = \"Sport_QA/test_Images\"\n",
    "test_im_path = [os.path.join(test_im_path,x) for x in os.listdir(test_im_path)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(full_path , annotations_list, include_masks=False):\n",
    "    \n",
    "    with tf.gfile.GFile(full_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "        \n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    \n",
    "    image = PIL.Image.open(encoded_jpg_io)\n",
    "    image_width = image.size[0]\n",
    "    image_height = image.size[1]\n",
    "    filename = full_path.split(\"/\")[-1]\n",
    "    key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "    \n",
    "    xmin = []\n",
    "    xmax = []\n",
    "    ymin = []\n",
    "    ymax = []\n",
    "    is_crowd = []\n",
    "    category_names = []\n",
    "    category_ids = []\n",
    "    area = []\n",
    "    encoded_mask_png = []\n",
    "    num_annotations_skipped = 0\n",
    "    \n",
    "#     for anno in  annotations_list: \n",
    "        \n",
    "        \n",
    "            \n",
    "#         xmin.append(float(x) / image_width)\n",
    "#         xmax.append(float(x + width) / image_width)\n",
    "#         ymin.append(float(y) / image_height)\n",
    "#         ymax.append(float(y + height) / image_height)\n",
    "#         category_id = int(object_annotations['category_id'])\n",
    "#         category_ids.append(category_id)\n",
    "#         category_names.append(category_index[category_id]['name'].encode('utf8'))\n",
    "#         area.append(object_annotations['area'])\n",
    "        \n",
    "    xmin = annotations_list['x_left']/float(image_width)\n",
    "    ymin = annotations_list['y_left']/float(image_height)\n",
    "    xmax = annotations_list['x_right']/float(image_width)\n",
    "    ymax = annotations_list['y_right']/float(image_height)\n",
    "    category_names = annotations_list['text']\n",
    "                \n",
    "    feature_dict = {\n",
    "        'image/height':\n",
    "        dataset_util.int64_feature(image_height),\n",
    "        'image/width':\n",
    "        dataset_util.int64_feature(image_width),\n",
    "        'image/filename':\n",
    "        dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "        'image/key/sha256':\n",
    "        dataset_util.bytes_feature(key.encode('utf8')),\n",
    "        'image/encoded':\n",
    "        dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format':\n",
    "        dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "        'image/object/bbox/xmin':\n",
    "        dataset_util.float_list_feature(xmin),\n",
    "        'image/object/bbox/xmax':\n",
    "        dataset_util.float_list_feature(xmax),\n",
    "        'image/object/bbox/ymin':\n",
    "        dataset_util.float_list_feature(ymin),\n",
    "        'image/object/bbox/ymax':\n",
    "        dataset_util.float_list_feature(ymax),\n",
    "        'image/object/class/text':\n",
    "        dataset_util.bytes_list_feature(category_names)\n",
    "        }\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "    return key, example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_anno_sport_qa(filename, h, w):\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        \n",
    "        content = f.readlines()\n",
    "        \n",
    "    content = [x[1:-3].strip().split(\",\") for x in content]\n",
    "    \n",
    "    anno = {}\n",
    "    x_text = []\n",
    "    x_left = []\n",
    "    y_left = []\n",
    "    x_right = []\n",
    "    y_right = []\n",
    "    \n",
    "    for x in content:\n",
    "        x_text_ = x[0][1:-1].lower()\n",
    "        x_left_ = int(x[1].strip())\n",
    "        y_left_ = int(x[2].strip())\n",
    "        x_right_ = int(x[1].strip())\n",
    "        y_right_ = int(x[2].strip())\n",
    "        \n",
    "        if x_left_<0: x_left_=0\n",
    "        if y_left_<0: y_left_=0\n",
    "        if x_right_>w: x_right_=w\n",
    "        if y_right_>h: y_right_=h\n",
    "            \n",
    "        if x_right_ < x_left_ or y_right_ < y_left_ : pass\n",
    "        \n",
    "        else:\n",
    "            x_text.append(x_text_)\n",
    "            x_left.append(x_left_)\n",
    "            y_left.append(y_left_)\n",
    "            x_right.append(x_right_)\n",
    "            y_right.append(y_right_)\n",
    "    \n",
    "    anno['text'] = np.array(x_text)\n",
    "    anno['x_left'] = np.array(x_left)\n",
    "    anno['y_left'] = np.array(y_left)\n",
    "    anno['x_right'] = np.array(x_right)\n",
    "    anno['y_right'] =  np.array(y_right)\n",
    "    \n",
    "    return anno\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sport_qa_to_tfrecords(output_path):\n",
    "    \n",
    "    train_count = 0\n",
    "    test_count = 0\n",
    "    \n",
    "    train_writer = tf.python_io.TFRecordWriter('%s_train.tfrecord'%output_path)\n",
    "    val_writer = tf.python_io.TFRecordWriter('%s_val.tfrecord'%output_path)\n",
    "    \n",
    "    for i,train in enumerate(path):\n",
    "        imgpath = im_path[i]\n",
    "        \n",
    "        h,w,c = np.shape(cv2.imread(imgpath))\n",
    "        \n",
    "        img_label = read_anno_sport_qa(train, h, w)\n",
    "        \n",
    "        \n",
    "        key, example = create_tf_example(imgpath, img_label)\n",
    "        \n",
    "        \n",
    "        train_writer.write(example.SerializeToString())\n",
    "        train_count += 1\n",
    "        \n",
    "    for i,test in enumerate(test_path):\n",
    "        imgpath = im_path[i]\n",
    "        h,w,c = np.shape(cv2.imread(imgpath))\n",
    "        img_label = read_anno_sport_qa(test, h, w)\n",
    "        \n",
    "        \n",
    "        key, example = create_tf_example(imgpath, img_label)\n",
    "        \n",
    "        \n",
    "        val_writer.write(example.SerializeToString())\n",
    "        test_count += 1\n",
    "        \n",
    "    train_writer.close()\n",
    "    val_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_sport_qa_to_tfrecords(\"Sport_data/Sport_QA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
